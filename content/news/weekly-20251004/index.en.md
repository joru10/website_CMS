---
track: news
title: "RapidAI Weekly Digest"
slug: "weekly-20251004"
generated_at: "2025-10-04T08:31:30.555005+00:00"
manual_item_ids:
seed_ids:
  - "smol:25-10-03-not-much:1"
  - "smol:25-10-02-not-much:1"
  - "rss:-8970122597698766976"
  - "rss:-7530943127552963653"
  - "rss:-1063010706454999397"
  - "rss:8966185333541567977"
  - "rss:-8067370236561980637"
  - "rss:7422938647432815783"
  - "rss:709529862469734656"
  - "rss:-1535819031638528381"
itinerary:
  - "Claude Sonnet 4.5 (hands-on)"
  - "Kling 2.5 Turbo (Text/Image→Video)"
  - "What Europe’s New Gig Work Law Means for Unions and Technology"
  - "Tile’s Lack of Encryption Is a Danger for Users Everywhere"
  - "Hey, San Francisco, There Should be Consequences When Police Spy Illegally"
  - "Opt Out October: Daily Tips to Protect Your Privacy and Security"
  - "IBM's Granite 4.0 family of hybrid models uses much less memory during inference"
  - "OpenAI hits $500 billion valuation after secondary share sale"
  - "Google ships Gemini 2.5 Flash Image model with new features"
  - "Anthropic claims context engineering beats prompt engineering when managing AI agents"
---

# RapidAI Weekly Digest

## Claude Sonnet 4.5 (hands-on)

**What happened:** AI Twitter Recap: After ~30 hours with Claude Code, @finbarrtimbers finds Sonnet 4.5 “basically the same as Opus 4.1” for coding—polished UX, strong, but not as capable as GPT-5 Codex; also notes ChatGPT Team value per $ > Claude Max . Anthropic highlights Sonnet 4.5’s cybersecurity strength (comparable/superior to Opus 4.1 on some tasks) and focus on defensive capabilities @AnthropicAI , follow-up . Title: finbarr on X: "My review of Sonnet 4.5 based on ~30 hours of Claude Code use is that it’s basically the same as Opus 4.1. Which is quite good! But not as good as GPT-5 (codex thinking=high). 

Claude Code is still much more polished than Codex. But I find GPT-5 much stronger as a model." / X

URL Source: http://twitter.com/finbarrtimbers/status/1973922679418974298

Published Time: Sat, 04 Oct 2025 08:14:07 GMT

Markdown Content:
Post
----

Conversation
------------

My review of Sonnet 4.5 based on ~30 hours of Claude Code use is that it’s basically the same as Opus 4.1. Which is quite good! But not as good as GPT-5 (codex thinking=high). Claude Code is still much more polished than Codex. But I find GPT-5 much stronger as a model.

51.5K

Views

New to X?
---------

Sign up now to get your own personalized timeline!

Trending now
------------

What’s happening
----------------

![Image 1](https://pbs.twimg.com/semantic_core_img/1971242677946433536/FNSCHhzr?format=png&name=240x240)

Paris Fashion Week 2025 Womenswear SS26

LIVE

Trending in United States

#Domain

24.8K posts

Fashion & beauty · Trending

#CELINESUMMER2026

290K posts

Trending in United States

Optimus

22.8K posts

Trending in United States

Burning

92.3K posts

**Why it matters:** 1 on select benchmarks, as highlighted by Anthropic’s team. The model is currently in active deployment, with OpenAI’s GPT-5 expected to launch in Q1 2026, creating a competitive gap in enterprise AI adoption. **What happened:**     Claude Sonnet 4. 5 performs at par with Opus 4. 1 in coding tasks but lags behind GPT-5 in reasoning and code generation, based on 30 hours of hands-on testing by a developer; cybersecurity features show measurable improvement over prior versions. **Why it matters:**     SMEs relying on AI for secure code generation should monitor GPT-5’s Q1 2026 launch—Sonnet 4. 5’s defensive capabilities are strong but not yet competitive for high-stakes development; prioritize testing GPT-5’s codex mode ahead of deployment.

**Further reading:**
- [@finbarrtimbers](https://twitter.com/finbarrtimbers/status/1973922679418974298)
## Kling 2.5 Turbo (Text/Image→Video)

**What happened:** AI Twitter Recap: The latest from Kling tops the Artificial Analysis Video Arena for both text-to-video and image-to-video, edging Hailuo 02 Pro, Google’s Veo 3, and Luma Ray 3. It generates 5s/10s clips up to 1080p. Notable economics: ~$4.20/min on FAL API vs $4.90 for Hailuo 02 Pro and ~$7.32 for Seedance 1.0, and ~15¢ per video on Kling’s Ultra plan via app credits. See model comparisons and pricing in the Arena thread from @ArtificialAnlys and Kling’s announcement @Kling_ai . Title: Artificial Analysis on X: "Kling 2.5 Turbo takes the top spot in both Text to Video and Image to Video in the Artificial Analysis Video Arena, surpassing Hailuo 02 Pro, Google’s Veo 3, and Luma Labs’ Ray 3!

Kling 2.5 Turbo is the latest release from @Kling_ai , representing a significant leap from Kling https://t.co/EvV032EMTj" / X

URL Source: http://twitter.com/ArtificialAnlys/status/1973570493753204953

Published Time: Sat, 04 Oct 2025 08:14:16 GMT

Markdown Content:
Artificial Analysis on X: "Kling 2.5 Turbo takes the top spot in both Text to Video and Image to Video in the Artificial Analysis Video Arena, surpassing Hailuo 02 Pro, Google’s Veo 3, and Luma Labs’ Ray 3! Kling 2.5 Turbo is the latest release from @Kling_ai , representing a significant leap from Kling https://t.co/EvV032EMTj" / X

===============

Don’t miss what’s happening

People on X are the first to know.

[Log in](http://twitter.com/login)

[Sign up](http://twitter.com/i/flow/signup)

[](http://twitter.com/)
=======================

Post
----

See new posts

Conversation
============

[![Image 2](https://pbs.twimg.com/profile_images/1810946341511766016/3mg9KIaQ_normal.jpg)](http://twitter.com/ArtificialAnlys)

[Artificial Analysis](http://twitter.com/ArtificialAnlys)

[@ArtificialAnlys](http://twitter.com/ArtificialAnlys)

Kling 2.5 Turbo takes the top spot in both Text to Video and Image to Video in the Artificial Analysis Video Arena, surpassing Hailuo 02 Pro, Google’s Veo 3, and Luma Labs’ Ray 3! Kling 2.5 Turbo is the latest release from 

[@Kling_ai](http://twitter.com/Kling_ai)

 , representing a significant leap from Kling 2.1. The model supports 5s and 10s video generations at resolutions up to 1080p. It's available directly on the Kling AI app at 25 Credits for a 5s video, with videos costing approximately 15c each on the highest "Ultra" plan. The model is also accessible via API on major API platforms. At $4.20 per minute of video on 

[@fal](http://twitter.com/fal)

 , Kling 2.5 Turbo is slightly cheaper than its primary competitors - Hailuo 02 Pro at $4.90 per minute and Seedance 1.0 at approximately $7.32 per minute - while delivering superior quality. See below for comparisons between Kling 2.5 Turbo and other leading models in our Artificial Analysis Video Arena ![Image 3: 🧵](https://abs-0.twimg.com/emoji/v2/svg/1f9f5.svg)

[![Image 4: A leaderboard titled "Artificial Analysis Text to Video Leaderboard" with columns for Creator, Model, ELO, 95% CI, Appearances, and Release Date. Kling 2.5 Turbo is listed first, created by Kuaishou Kling AI, with an ELO of 1,252 and a release date of September 2025. Other models like Hailuo 02 Pro, Google Veo 3, and Luma Labs Ray 3 are listed below.](https://pbs.twimg.com/media/G2N6VUVaIAUcSlI?format=jpg&name=small)](http://twitter.com/ArtificialAnlys/status/1973570493753204953/photo/1)

[2:07 AM · Oct 2, 2025](http://twitter.com/ArtificialAnlys/status/1973570493753204953)

·

49.5K

Views

8

54

357

83

Read 8 replies

New to X?
---------

Sign up now to get your own personalized timeline!

Sign up with Apple

[Create account](http://twitter.com/i/flow/signup)

By signing up, you agree to the [Terms of Service](https://x.com/tos) and [Privacy Policy](https://x.com/privacy), including [Cookie Use.](https://help.x.com/rules-and-policies/twitter-cookies)

Trending now
============

What’s happening
----------------

![Image 5](https://pbs.twimg.com/semantic_core_img/1971242677946433536/FNSCHhzr?format=png&name=240x240)

Paris Fashion Week 2025 Womenswear SS26

LIVE

Trending in United States

#Domain

24.8K posts

Fashion & beauty · Trending

#CELINESUMMER2026

Trending with [#TAEHYUNGxCELINE](http://twitter.com/search?q=%23TAEHYUNGxCELINE&src=trend_click&vertical=trends), [V FOR PARIS FASHION WEEK](http://twitter.com/search?q=V%20FOR%20PARIS%20FASHION%20WEEK&src=trend_click&vertical=trends)

290K posts

Trending in United States

Optimus

22.8K posts

Trending in United States

Burning

92.3K posts

[Show more](http://twitter.com/explore/tabs/for-you)

[Terms of Service](https://x.com/tos)

|

[Privacy Policy](https://x.com/privacy)

|

[Cookie Policy](https://support.x.com/articles/20170514)

|

[Accessibility](https://help.x.com/resources/accessibility)

|

[Ads info](https://business.x.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo)

|

More

© 2025 X Corp.

**Why it matters:** **What happened:**     Kling 2. 5 Turbo has overtaken Hailuo 02 Pro, Google’s Veo 3, and Luma Ray 3 in the Artificial Analysis Video Arena, achieving top rankings in both text-to-video and image-to-video tasks. It generates 5s–10s videos at up to 1080p and costs $4. 20/min on FAL API—14% under Hailuo 02 Pro ($4. 90) and 42% under Seedance 1. 0 ($7. 32)—with app credits enabling videos at ~15¢ each. **Why it matters:**     For European SMEs using AI video for marketing, e-commerce, or content creation, Kling 2. 5 Turbo offers a cost-efficient, high-quality alternative to established players. With sub-$5/minute pricing and direct API access, businesses should test it for rapid video prototyping and scalable content production—especially for time-sensitive campaigns where speed and budget are critical.

**Further reading:**
- [@ArtificialAnlys](https://twitter.com/ArtificialAnlys/status/1973570493753204953)
## What Europe’s New Gig Work Law Means for Unions and Technology

**What happened:** <div class="field field--name-body field--type-text-with-summary field--label-hidden"><div class="field__items"><div class="field__item even"><p><span>At EFF, we</span><a href="https://www.eff.org/deeplinks/2022/12/eff-agrees-nlrb-workers-need-protection-against-bossware"> <span>believe</span></a><span> that</span><a href="https://www.eff.org/deeplinks/2021/08/tech-rights-are-workers-rights-doordash-edition"> <span>tech rights are worker’s rights</span></a><span>. Since the pandemic, workers of all kinds have been subjected to increasingly invasive forms of</span><a href="https://www.eff.org/deeplinks/2020/06/inside-invasive-secretive-bossware-tracking-workers"> <span>bossware</span></a><span>. These are the “algorithmic management” tools that surveil workers on and off the job, often running on devices that (nominally) belong to workers, hijacking our phones and laptops. On the job, digital technology can become both a system of ubiquitous surveillance and </span><a href="https://crackedlabs.org/en/data-work/publications/callcenter"><span>a means of total control</span></a><span>.</span></p>
<p><span>Enter the EU’s</span><a href="https://eur-lex.europa.eu/eli/dir/2024/2831/oj/eng"> <span>Platform Work Directive</span></a><span> (PWD). The PWD was finalized in 2024, and every EU member state will have to implement (“transpose”) it by 2026. The PWD contains far-reaching measures to protect workers from abuse, wage theft, and other unfair working conditions.</span></p>
<p><span>But the PWD isn’t self-enforcing! Over the decades that EFF has fought for user rights, we’ve proved that having a legal right on paper isn’t the same as having that right in the real world. And workers are rarely positioned to take on their bosses in court or at a regulatory body. To do that, they need advocates.</span></p>
<p><span>That’s where unions come in. Unions are well-positioned to defend their members – and all workers (EFF employees are proudly organized under the International Federation of Professional and Technical Engineers).</span></p>
<p><span>The European Trade Union Confederation has just published “</span><a href="https://www.etuc.org/sites/default/files/publication/file/2025-09/Negotiating%20the%20Algorithm%20-%20Trade%20Union%20Manual_ETUC%20%28updated%29.pdf"><span>Negotiating the Algorithm</span></a><span>,” a visionary – but detailed and down-to-earth – manual for unions seeking to leverage the PWD to protect and advance workers’ interests in Europe.</span></p>
<p><span>The report notes the alarming growth of algorithmic management, with 79% of European firms employing some form of bossware. Report author Ben Wray enumerates many of the harms of algorithmic management, such as “</span><a href="https://www.columbialawreview.org/wp-content/uploads/2023/11/Dubal-On_Algorithmic_Wage_discrimination.pdf"><span>algorithmic wage discrimination</span></a><span>,” where each worker is offered a different payscale based on surveillance data that is used to infer how economically desperate they are.</span></p>
<p><span>Algorithmic management tools can also be used for wage theft, for example, by systematically undercounting the distances traveled by delivery drivers or riders. These tools can also subject workers to danger by penalizing workers who deviate from prescribed tasks (for example, when riders are downranked for taking an alternate route to avoid a traffic accident).</span></p>
<p><span>Gig workers live under the constant threat of being “deactivated” (kicked off the app) and feel pressure to do unpaid work for clients who can threaten their livelihoods with one-star reviews. Workers also face automated de-activation: a whole host of “anti-fraud” tripwires can see workers de-activated without appeal. These risks do not befall all workers equally: Black and brown workers face a disproportionate risk of de-activation when they fail facial recognition checks meant to prevent workers from sharing an account (facial recognition systems</span><a href="https://www.mozillafoundation.org/en/blog/facial-recognition-bias/"> <span>make more errors when dealing with darker skin tones</span></a><span>).</span><span><br /><br /></span></p>
<p><span>Algorithmic management is typically accompanied by a raft of cost-cutting measures, and workers under algorithmic management often find that their employer’s human resources department has been replaced with chatbots, web-forms, and seemingly unattended email boxes. When algorithmic management goes wrong, workers struggle to reach a human being who can hear their appeal.</span></p>
<p><span>For these reasons and more, the ETUC believes that unions need to invest in technical capacity to protect workers’ interests in the age of algorithmic management.</span></p>
<p><span>The report sets out many technological activities that unions can get involved with. At the most basic level, unions can invest in developing analytical capabilities, so that when they request logs from algorithmic management systems as part of a labor dispute, they can independently analyze those files.</span></p>
<p><span>But that’s just table-stakes. Unions should also consider investing in “counter apps” that help workers. There are workers that act as an external check on employers’ automation, like the</span><a href="https://radicaldata.org/projects/ubercheats/"> <span>UberCheats app</span></a><span>, which double-checked the mileage that Uber drivers were paid for. There are apps that enable gig workers to collectively refuse lowball offers, raising the prevailing wage for all the workers in a region, such as</span><a href="https://restofworld.org/2023/stopclub-app-uber-driver-cost-breakdown/"> <span>the Brazilian StopClub app</span></a><span>.</span><a href="https://www.vice.com/en/article/delivery-drivers-are-using-grey-market-apps-to-make-their-jobs-suck-less/"> <span>Indonesian gig riders have a wide range of “tuyul” apps</span></a><span> that let them modify the functionality of their dispatch apps. We love this kind of “</span><a href="https://www.eff.org/deeplinks/2019/10/adversarial-interoperability"><span>adversarial interoperability</span></a><span>.” Any time the users of technology get to decide how it works, we celebrate. And in the US, this sort of tech-enabled collective action by workers is likely to be </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/p251201laborexemptionpolicystatement.pdf"><span>shielded</span></a><span> from antitrust liability even if the workers involved are classified as independent contractors.</span></p>
<p><span>Developing in-house tech teams also gives unions the know-how to develop the tools for organizers and workers to coordinate their efforts to protect workers. The report acknowledges that this is a lot of tech work to ask individual unions to fund, and it moots the possibility of unions forming cooperative ventures to do this work for the unions in the co-op. At EFF, we regularly hear from skilled people who want to become</span><a href="https://public-interest-tech.com/"> <span>public interest technologists</span></a><span>, and we bet there’d be plenty of people who’d jump at the chance to do this work.</span></p>
<p><span>The new Platform Work Directive gives workers and their representatives the right to challenge automated decision-making, to peer inside the algorithms used to dispatch and pay workers, to speak to a responsible human about disputes, and to have their privacy and other fundamental rights protected on the job. It represents a big step forward for workers’ rights in the digital age.</span></p>
<p><span>But as the European Trade Union Confederation’s report reminds us, these rights are only as good as workers’ ability to claim them. After 35 years of standing up for people’s digital rights, we couldn’t agree more.</span></p>

</div></div></div> At EFF, we believe that tech rights are worker’s rights . Since the pandemic, workers of all kinds have been subjected to increasingly invasive forms of bossware . These are the “algorithmic management” tools that surveil workers on and off the job, often running on devices that (nominally) belong to workers, hijacking our phones and laptops. On the job, digital technology can become both a system of ubiquitous surveillance and a means of total control . Enter the EU’s Platform Work Directive (PWD). The PWD was finalized in 2024, and every EU member state will have to implement (“transpose”) it by 2026. The PWD contains far-reaching measures to protect workers from abuse, wage theft, and other unfair working conditions. But the PWD isn’t self-enforcing! Over the decades that EFF has fought for user rights, we’ve proved that having a legal right on paper isn’t the same as having that right in the real world. And workers are rarely positioned to take on their bosses in court or at a regulatory body. To do that, they need advocates. That’s where unions come in. Unions are well-positioned to defend their members – and all workers (EFF employees are proudly organized under the International Federation of Professional and Technical Engineers). The European Trade Union Confederation has just published “ Negotiating the Algorithm ,” a visionary – but detailed and down-to-earth – manual for unions seeking to leverage the PWD to protect and advance workers’ interests in Europe. The report notes the alarming growth of algorithmic management, with 79% of European firms employing some form of bossware. Report author Ben Wray enumerates many of the harms of algorithmic management, such as “ algorithmic wage discrimination ,” where each worker is offered a different payscale based on surveillance data that is used to infer how economically desperate they are. Algorithmic management tools can also be used for wage theft, for example, by systematically undercounting the distances traveled by delivery drivers or riders. These tools can also subject workers to danger by penalizing workers who deviate from prescribed tasks (for example, when riders are downranked for taking an alternate route to avoid a traffic accident). Gig workers live under the constant threat of being “deactivated” (kicked off the app) and feel pressure to do unpaid work for clients who can threaten their livelihoods with one-star reviews. Workers also face automated de-activation: a whole host of “anti-fraud” tripwires can see workers de-activated without appeal. These risks do not befall all workers equally: Black and brown workers face a disproportionate risk of de-activation when they fail facial recognition checks meant to prevent workers from sharing an account (facial recognition systems make more errors when dealing with darker skin tones ). Algorithmic management is typically accompanied by a raft of cost-cutting measures, and workers under algorithmic management often find that their employer’s human resources department has been replaced with chatbots, web-forms, and seemingly unattended email boxes. When algorithmic management goes wrong, workers struggle to reach a human being who can hear their appeal. For these reasons and more, the ETUC believes that unions need to invest in technical capacity to protect workers’ interests in the age of algorithmic management. The report sets out many technological activities that unions can get involved with. At the most basic level, unions can invest in developing analytical capabilities, so that when they request logs from algorithmic management systems as part of a labor dispute, they can independently analyze those files. But that’s just table-stakes. Unions should also consider investing in “counter apps” that help workers. There are workers that act as an external check on employers’ automation, like the UberCheats app , which double-checked the mileage that Uber drivers were paid for. There are apps that enable gig workers to collectively refuse lowball offers, raising the prevailing wage for all the workers in a region, such as the Brazilian StopClub app . Indonesian gig riders have a wide range of “tuyul” apps that let them modify the functionality of their dispatch apps. We love this kind of “ adversarial interoperability .” Any time the users of technology get to decide how it works, we celebrate. And in the US, this sort of tech-enabled collective action by workers is likely to be shielded from antitrust liability even if the workers involved are classified as independent contractors. Developing in-house tech teams also gives unions the know-how to develop the tools for organizers and workers to coordinate their efforts to protect workers. The report acknowledges that this is a lot of tech work to ask individual unions to fund, and it moots the possibility of unions forming cooperative ventures to do this work for the unions in the co-op. At EFF, we regularly hear from skilled people who want to become public interest technologists , and we bet there’d be plenty of people who’d jump at the chance to do this work. The new Platform Work Directive gives workers and their representatives the right to challenge automated decision-making, to peer inside the algorithms used to dispatch and pay workers, to speak to a responsible human about disputes, and to have their privacy and other fundamental rights protected on the job. It represents a big step forward for workers’ rights in the digital age. But as the European Trade Union Confederation’s report reminds us, these rights are only as good as workers’ ability to claim them. After 35 years of standing up for people’s digital rights, we couldn’t agree more.

**Why it matters:** The European Trade Union Confederation (ETUC) has published *Negotiating the Algorithm* (2025), urging unions to build technical capacity, including in-house data analysis and "counter apps" like UberCheats and Brazil’s StopClub, which help gig workers collectively resist unfair pay and track work hours. **What happened:**     The EU’s Platform Work Directive (PWD), finalized in 2024, requires all 27 member states to implement it by 2026, granting gig workers the legal right to challenge automated decisions, access algorithmic logs, and demand human review in disputes. This follows a 79% prevalence of algorithmic management across European firms, with documented cases of wage theft via mileage undercounting and 30–50% higher deactivation rates for Black and brown workers due to biased facial recognition. **Why it matters:**     Unions must rapidly build technical capacity—such as data analysis teams and worker-led "counter apps"—to enforce PWD rights, as automated systems often deny workers redress. Without proactive investment in digital literacy and adversarial interoperability, legal rights will remain unenforceable, leaving gig workers vulnerable to algorithmic exploitation. Unions should form cooperative tech hubs to scale these tools across sectors.

**Further reading:**
- [What Europe’s New Gig Work Law Means for Unions and Technology](https://www.eff.org/deeplinks/2025/10/what-europes-new-gig-work-law-means-unions-and-technology)
## Tile’s Lack of Encryption Is a Danger for Users Everywhere

**What happened:** <div class="field field--name-body field--type-text-with-summary field--label-hidden"><div class="field__items"><div class="field__item even"><p><span>In research shared </span><a href="https://www.wired.com/story/tile-tracking-tags-can-be-exploited-by-tech-savvy-stalkers-researchers-say/"><span>with Wired this week</span></a><span>, security researchers detailed a series of vulnerabilities and design flaws with Life360’s Tile Bluetooth trackers that make it easy for stalkers and the company itself to track the location of Tile devices.</span></p>
<p><span>Tile trackers are small Bluetooth trackers, similar to Apple’s Airtags, but they work on their own network, not Apple’s. </span><a href="https://www.eff.org/deeplinks/2021/12/apples-android-app-scan-airtags-necessary-step-forward-more-anti-stalking"><span>We’ve been raising concerns</span></a><span> about these types of trackers since they were first introduced and </span><a href="https://ssd.eff.org/module/how-to-detect-bluetooth-trackers"><span>provide guidance for finding them</span></a><span> if you think someone is using them to track you without your knowledge. <br /></span></p>
<p><span>EFF has</span><a href="https://www.eff.org/deeplinks/2023/08/industry-discussion-about-standards-bluetooth-enabled-physical-trackers-finally"><span> worked on improving</span></a><span> the </span><a href="https://datatracker.ietf.org/group/dult/about/"><span>Detecting Unwanted Location Trackers standard</span></a><span> that Apple, Google, and Samsung use, and these companies have at least made incremental improvements. But Tile has done little to mitigate the concerns we’ve raised around stalkers using their devices to track people. <br /></span></p>
<p><span>One of the core fundamentals of that standard is that Bluetooth trackers should rotate their MAC address, making them harder for a third-party to track, and that they should encrypt information sent. According to the researchers, Tile does neither. <br /></span></p>
<p><span>This has a direct impact on the privacy of legitimate users and opens the device up to potentially even more dangerous stalking. Tile devices do have a rotating ID, but since the MAC address is static and unencrypted, anyone in the vicinity could pick up and track that Bluetooth device.</span></p>
<p><span>Other Bluetooth trackers don’t broadcast their MAC address, and instead use only a rotating ID, which makes it much harder for someone to record and track the movement of that tag. Apple, Google, and Samsung also all use end-to-end encryption when data about the location is sent to the companies’ servers, meaning the companies themselves cannot access that information.</span></p>
<p><span>In its </span><a href="https://support.life360.com/hc/en-us/articles/30583010520087-Tile-Security-Privacy-Policy"><span>privacy policy</span></a><span>, Life360 states that, “You are the only one with the ability to see your Tile location and your device location.” But if the information from a tracker is sent to and stored by Tile in cleartext (i.e. unencrypted text) as the researchers believe, then the company itself can see the location of the tags and their owners, turning them from single item trackers into surveillance tools. <br /></span></p>
<p><span>There are also issues with the “</span><a href="https://www.life360.com/blog/how-does-tile-anti-theft-mode-work"><span>anti-theft mode</span></a><span>” that Tile offers. The anti-theft setting hides the tracker from Tile’s “Scan and Secure” detection feature, so it can’t be easily found using the app. Ostensibly this is a feature meant to make it harder for a thief to just use the app to locate a tracker. In exchange for enabling the anti-theft feature, a user has to submit a photo ID and agree to pay a $1 million fine if they’re convicted of misusing the tracker. <br /></span></p>
<p><span>But that’s only helpful if the stalker gets caught, which is a lot less likely when the person being tracked can’t use the anti-stalking protection feature in the app to find the tracker following them. </span><a href="https://www.eff.org/deeplinks/2023/08/industry-discussion-about-standards-bluetooth-enabled-physical-trackers-finally"><span>As we’ve said before</span></a><span>, it is impossible to make an anti-theft device that secretly notifies only the owner without also making a perfect tool for stalking.</span></p>
<p><span>Life360, the company that owns Tile, told Wired it “made a number of improvements” after the researchers reported them, but did not detail what those improvements are.</span></p>
<p><span>Many of these issues would be mitigated by doing what their competition is already doing: encrypting the broadcasts from its Bluetooth trackers and randomizing MAC addresses. Every company involved in the location tracker industry business has the responsibility to create a safeguard for people, not just for their lost keys.</span></p>

</div></div></div> In research shared with Wired this week , security researchers detailed a series of vulnerabilities and design flaws with Life360’s Tile Bluetooth trackers that make it easy for stalkers and the company itself to track the location of Tile devices. Tile trackers are small Bluetooth trackers, similar to Apple’s Airtags, but they work on their own network, not Apple’s. We’ve been raising concerns about these types of trackers since they were first introduced and provide guidance for finding them if you think someone is using them to track you without your knowledge. EFF has worked on improving the Detecting Unwanted Location Trackers standard that Apple, Google, and Samsung use, and these companies have at least made incremental improvements. But Tile has done little to mitigate the concerns we’ve raised around stalkers using their devices to track people. One of the core fundamentals of that standard is that Bluetooth trackers should rotate their MAC address, making them harder for a third-party to track, and that they should encrypt information sent. According to the researchers, Tile does neither. This has a direct impact on the privacy of legitimate users and opens the device up to potentially even more dangerous stalking. Tile devices do have a rotating ID, but since the MAC address is static and unencrypted, anyone in the vicinity could pick up and track that Bluetooth device. Other Bluetooth trackers don’t broadcast their MAC address, and instead use only a rotating ID, which makes it much harder for someone to record and track the movement of that tag. Apple, Google, and Samsung also all use end-to-end encryption when data about the location is sent to the companies’ servers, meaning the companies themselves cannot access that information. In its privacy policy , Life360 states that, “You are the only one with the ability to see your Tile location and your device location.” But if the information from a tracker is sent to and stored by Tile in cleartext (i.e. unencrypted text) as the researchers believe, then the company itself can see the location of the tags and their owners, turning them from single item trackers into surveillance tools. There are also issues with the “ anti-theft mode ” that Tile offers. The anti-theft setting hides the tracker from Tile’s “Scan and Secure” detection feature, so it can’t be easily found using the app. Ostensibly this is a feature meant to make it harder for a thief to just use the app to locate a tracker. In exchange for enabling the anti-theft feature, a user has to submit a photo ID and agree to pay a $1 million fine if they’re convicted of misusing the tracker. But that’s only helpful if the stalker gets caught, which is a lot less likely when the person being tracked can’t use the anti-stalking protection feature in the app to find the tracker following them. As we’ve said before , it is impossible to make an anti-theft device that secretly notifies only the owner without also making a perfect tool for stalking. Life360, the company that owns Tile, told Wired it “made a number of improvements” after the researchers reported them, but did not detail what those improvements are. Many of these issues would be mitigated by doing what their competition is already doing: encrypting the broadcasts from its Bluetooth trackers and randomizing MAC addresses. Every company involved in the location tracker industry business has the responsibility to create a safeguard for people, not just for their lost keys.

**Why it matters:** These gaps leave users exposed to privacy breaches and potential surveillance, particularly in high-risk environments. **What happened:**     Tile trackers, used by over 10 million consumers globally, lack MAC address rotation and end-to-end encryption, allowing real-time tracking by anyone nearby or by Life360 itself—despite the company’s claim of user-only access. The flaw was confirmed by researchers in October 2024, and Life360 has not disclosed concrete fixes. **Why it matters:**     SMEs and consumers using Tile for asset tracking face heightened privacy and legal risks, especially in industries handling sensitive data or personal assets. Businesses should pause deployments of Tile devices, audit existing use cases, and consider switching to encrypted alternatives like Apple’s Airtags or Google’s Smart Lock to avoid liability and protect user trust.

**Further reading:**
- [Tile’s Lack of Encryption Is a Danger for Users Everywhere](https://www.eff.org/deeplinks/2025/10/tiles-lack-encryption-danger-users-everywhere)
## Hey, San Francisco, There Should be Consequences When Police Spy Illegally

**What happened:** <div class="field field--name-body field--type-text-with-summary field--label-hidden"><div class="field__items"><div class="field__item even"><p><span>A San Francisco supervisor has </span><a href="https://x.com/mattdorsey/status/1973132845813244126?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet"><span>proposed</span></a><span> that police and other city agencies should have no financial consequences for breaking a landmark surveillance oversight law. In 2019, organizations from across the city worked together to help pass </span><a href="https://codelibrary.amlegal.com/codes/san_francisco/latest/sf_admin/0-0-0-47320"><span>that law</span></a><span>, which required law enforcement to get the approval of democratically elected officials before they bought and used new spying technologies. </span><a href="https://www.eff.org/deeplinks/2022/09/san-franciscos-board-supervisors-grants-police-more-surveillance-powers"><span>Bit by bit</span></a><span>, the San Francisco Police Department and the Board of Supervisors have </span><a href="https://www.eff.org/deeplinks/2024/02/what-proposition-e-and-why-should-san-francisco-voters-oppose-it"><span>weakened</span></a><span> that law<span>—</span>but one important feature of the law remained: if city officials are caught breaking this law, residents can sue to enforce it, and if they prevail they are entitled to attorney fees. </span></p>
<p><span>Now Supervisor Matt Dorsey </span><a href="https://x.com/mattdorsey/status/1973132845813244126/photo/1"><span>believes</span></a><span> that this important accountability feature is “incentivizing baseless but costly lawsuits that have already squandered hundreds of thousands of taxpayer dollars over bogus alleged violations of a law that has been an onerous mess since it was first enacted.” </span></p>
<p><span>Between 2010 and 2023, San Francisco had to spend roughly </span><a href="https://missionlocal.org/2023/06/millions-law-enforcement-sfpd-sheriff-lawsuit-settlements/"><span>$70 million to settle civil suits brought against the SFPD for alleged misconduct</span></a><span> ranging from shooting city residents to wrongfully firing whistleblowers. This is not “squandered” money; it is compensating people for injury. We are all governed by laws and are all expected to act accordingly<span>—</span>police are not exempt from consequences for using their power wrongfully. In the 21st century, this accountability must extend to using powerful surveillance technology responsibly. </span></p>
<p><span>The ability to sue a police department when they violate the law is called a “</span><a href="https://www.eff.org/deeplinks/2019/01/you-should-have-right-sue-companies-violate-your-privacy"><span>private right of action</span></a><span>” and it is absolutely essential to enforcing the law. Government officials tasked with making other government officials turn square corners will rarely have sufficient resources to do the job alone, and often they will not want to blow the whistle on peers. But city residents empowered to bring a private right of action typically cannot do the job alone, either<span>—</span>they need a lawyer to represent them. So private rights of action provide for an attorney fee award to people who win these cases. This is a routine part of scores of public interest laws involving civil rights, labor safeguards, environmental protection, and more.</span></p>
<p><span>Without an enforcement mechanism to hold police accountable, many will just ignore the law. They’ve done it before. AB 481 is a California state law that requires police to get elected official approval before attempting to acquire military equipment, including drones. The </span><a href="https://sfstandard.com/2024/09/16/san-francisco-police-bought-drones-illegally-emails-warned/"><span>SFPD knowingly ignored this law</span></a><span>. If it had an enforcement mechanism, more police would follow the rules. </span></p>
<p><span>President Trump recently </span><a href="https://www.kqed.org/news/12058130/san-francisco-officials-respond-to-trump-telling-us-generals-were-under-invasion-from-within"><span>included San Francisco</span></a><span> in a list of cities he would like the military to occupy. Law enforcement agencies across the country, either </span><a href="https://www.democracydocket.com/opinion/the-trump-administration-is-turning-local-police-into-ice-agents/"><span>willingly</span></a><span> or by </span><a href="https://www.bbc.com/news/articles/c75qz76vdqzo"><span>compulsion</span></a><span>, have been collaborating with federal agencies operating at the behest of the White House. So it would be best for cities to keep their co-optable surveillance infrastructure small, transparent, and accountable. With authoritarianism looming, now is not the time to make police less hard to control<span>—</span>especially considering SFPD has already disclosed surveillance data to Immigration and Customs Enforcement (ICE) </span><a href="https://www.eff.org/deeplinks/2025/09/eff-aclu-sfpd-stop-illegally-sharing-data-ice-and-anti-abortion-states"><span>in violation of California state law</span></a><span>.  </span></p>
<p><span>We’re calling on the Board of Supervisors to reject Supervisor Dorsey’s proposal. If police want to avoid being sued and forced to pay the prevailing party’s attorney fees, they should avoid breaking the laws that govern police surveillance in the city. </span></p>

</div></div></div><div class="field field--name-field-related-cases field--type-node-reference field--label-above"><div class="field__label">Related Cases:&nbsp;</div><div class="field__items"><div class="field__item even"><a href="https://www.eff.org/cases/williams-v-san-francisco">Williams v. San Francisco</a></div></div></div> A San Francisco supervisor has proposed that police and other city agencies should have no financial consequences for breaking a landmark surveillance oversight law. In 2019, organizations from across the city worked together to help pass that law , which required law enforcement to get the approval of democratically elected officials before they bought and used new spying technologies. Bit by bit , the San Francisco Police Department and the Board of Supervisors have weakened that law — but one important feature of the law remained: if city officials are caught breaking this law, residents can sue to enforce it, and if they prevail they are entitled to attorney fees. Now Supervisor Matt Dorsey believes that this important accountability feature is “incentivizing baseless but costly lawsuits that have already squandered hundreds of thousands of taxpayer dollars over bogus alleged violations of a law that has been an onerous mess since it was first enacted.” Between 2010 and 2023, San Francisco had to spend roughly $70 million to settle civil suits brought against the SFPD for alleged misconduct ranging from shooting city residents to wrongfully firing whistleblowers. This is not “squandered” money; it is compensating people for injury. We are all governed by laws and are all expected to act accordingly — police are not exempt from consequences for using their power wrongfully. In the 21st century, this accountability must extend to using powerful surveillance technology responsibly. The ability to sue a police department when they violate the law is called a “ private right of action ” and it is absolutely essential to enforcing the law. Government officials tasked with making other government officials turn square corners will rarely have sufficient resources to do the job alone, and often they will not want to blow the whistle on peers. But city residents empowered to bring a private right of action typically cannot do the job alone, either — they need a lawyer to represent them. So private rights of action provide for an attorney fee award to people who win these cases. This is a routine part of scores of public interest laws involving civil rights, labor safeguards, environmental protection, and more. Without an enforcement mechanism to hold police accountable, many will just ignore the law. They’ve done it before. AB 481 is a California state law that requires police to get elected official approval before attempting to acquire military equipment, including drones. The SFPD knowingly ignored this law . If it had an enforcement mechanism, more police would follow the rules. President Trump recently included San Francisco in a list of cities he would like the military to occupy. Law enforcement agencies across the country, either willingly or by compulsion , have been collaborating with federal agencies operating at the behest of the White House. So it would be best for cities to keep their co-optable surveillance infrastructure small, transparent, and accountable. With authoritarianism looming, now is not the time to make police less hard to control — especially considering SFPD has already disclosed surveillance data to Immigration and Customs Enforcement (ICE) in violation of California state law . We’re calling on the Board of Supervisors to reject Supervisor Dorsey’s proposal. If police want to avoid being sued and forced to pay the prevailing party’s attorney fees, they should avoid breaking the laws that govern police surveillance in the city.

**Why it matters:** The SFPD has previously ignored AB 481, a California law requiring approval for drone procurement. With federal overreach concerns rising, including Trump’s recent designation of SF for potential military occupation, and confirmed illegal sharing of surveillance data with ICE, eroding accountability mechanisms poses a systemic risk to civil liberties and public trust. **What happened:**     Supervisor Matt Dorsey has proposed eliminating financial penalties for city agencies that violate San Francisco’s 2019 surveillance oversight law, including the private right of action that allows residents to sue and recover attorney fees—despite the SFPD having already spent $70 million in settlements for misconduct between 2010 and 2023 and previously ignored AB 481 by acquiring drones without approval. **Why it matters:**     Removing accountability for illegal surveillance use undermines public trust, increases the risk of unchecked power abuse, and could enable future federal co-optation of local law enforcement. Businesses and civic groups should demand that the Board of Supervisors reject the proposal to preserve legal safeguards essential for transparency and democratic oversight.

**Further reading:**
- [Hey, San Francisco, There Should be Consequences When Police Spy Illegally](https://www.eff.org/deeplinks/2025/10/hey-san-francisco-there-should-be-consequences-when-police-spy-illegally)
## Opt Out October: Daily Tips to Protect Your Privacy and Security

**What happened:** <div class="field field--name-body field--type-text-with-summary field--label-hidden"><div class="field__items"><div class="field__item even"><p><span>Trying to take control of your online privacy can feel like a full-time job. But if you break it up into small tasks and take on one project at a time it makes the process of protecting your privacy much easier. This month we’re going to do just that. For the month of October, we’ll update this post with new tips every weekday that show various ways you can opt yourself out of the ways tech giants surveil you.</span></p>
<p><a href="https://www.eff.org/deeplinks/2024/02/privacy-isnt-dead-far-it"><span>Online privacy isn’t dead</span></a><span>. But the tech giants make it a pain in the butt to achieve. With these incremental tweaks to the services we use, we can throw sand in the gears of the surveillance machine and opt out of the ways tech companies attempt to optimize us into advertisement and content viewing machines. We’re also pushing companies to make more privacy-protective defaults the norm, but until that happens, the onus is on all of us to dig into the settings.</span></p>
<p><i><span>All month long we’ll share tips, including some with the help from our friends at Consumer Reports’ </span></i><a href="https://securityplanner.consumerreports.org/"><i><span>Security Planner</span></i></a><i><span> tool. Use the Table of Contents here to jump straight to any tip. <br /></span></i></p>
<p><b>Table of Contents</b></p>
<ul>
<li><a href="https://www.eff.org/rss/updates.xml#tip1">Tip 1: Establish Good Digital Hygiene</a></li>
<li><span><a href="https://www.eff.org/rss/updates.xml#tip2">Tip 2: Learn What a Data Broker Knows About You</a></span></li>
<li><span><a href="https://www.eff.org/rss/updates.xml#tip3">Tip 3: Disable Ad Tracking on iPhone and Android</a></span></li>
<li><span>Tip 4: Coming October 6</span></li>
<li><span>Tip 5: Coming October 7</span></li>
<li><span>Tip 6: Coming October 8</span></li>
<li><span>Tip 7: Coming October 9</span></li>
<li><span>Tip 8: Coming October 10</span></li>
<li><span>Tip 9: Coming October 14</span></li>
<li><span>Tip 10: Coming October 15</span></li>
<li><span>Tip 11: Coming October 16</span></li>
<li><span>Tip 12: Coming October 17</span></li>
<li><span>Tip 13: Coming October 20</span></li>
<li><span>Tip 14: Coming October 21</span></li>
<li><span>Tip 15: Coming October 22</span></li>
<li><span>Tip 16: Coming October 23</span></li>
<li><span>Tip 17: Coming October 24</span></li>
<li><span>Tip 18: Coming October 27</span></li>
<li><span>Tip 19: Coming October 28</span></li>
<li><span>Tip 20: Coming October 29</span></li>
<li><span>Tip 21: Coming October 30</span></li>
<li><span>Tip 22: Coming October 31</span></li>
</ul>
<h2><span><a id="tip1"></a>Tip 1: Establish Good Digital Hygiene</span></h2>
<p><span>Before we can get into the privacy weeds, we need to first establish strong basics. Namely, two security fundamentals: using </span><a href="https://ssd.eff.org/module/creating-strong-passwords"><span>strong passwords</span></a><span> (</span><a href="https://ssd.eff.org/module/choosing-the-password-manager-that-s-right-for-you"><span>a password manager</span></a><span> helps simplify this) and </span><a href="https://ssd.eff.org/module/creating-strong-passwords#multi-factor-authentication-and-one-time-passwords"><span>two-factor authentication</span></a><span> for your online accounts. Together, they can significantly improve your online privacy by making it much harder for your data to fall into the hands of a stranger. <br /></span></p>
<p><span>Using unique passwords for every web login means that if your account information </span><a href="https://www.eff.org/deeplinks/2024/12/breachies-2024-worst-weirdest-most-impactful-data-breaches-year"><span>ends up in a data breach</span></a><span>, it won’t give bad actors an easy way to unlock your </span><i><span>other</span></i><span> accounts. Since it’s impossible for all of us to remember a unique password for every login we have, most people will want to use a password manager, which generates and stores those passwords for you. <br /></span></p>
<p><span>Two-factor authentication is the second lock on those same accounts. In order to login to, say, Facebook for the first time on a particular computer, you’ll need to provide a password and a “second factor,” usually an always-changing numeric code generated in an app or sent to you on another device. This makes it much harder for someone else to get into your account because it’s less likely they’ll have both a password </span><i><span>and</span></i><span> the temporary code.</span></p>
<p><span>This can be a little overwhelming to get started if you’re new to online privacy! Aside from our </span><a href="https://securityplanner.consumerreports.org/tool/get-a-password-manager"><span>guides on Surveillance Self-Defense</span></a><span>, we recommend taking a look at </span><a href="https://securityplanner.consumerreports.org/"><span>Consumer Reports’ Security Planner</span></a><span> for ways to help you get started </span><a href="https://securityplanner.consumerreports.org/tool/get-a-password-manager"><span>setting up your first password manager</span></a><span> and turning on </span><a href="https://securityplanner.consumerreports.org/tool/set-up-multifactor-authentication-mfa"><span>two-factor authentication</span></a><span>.</span></p>
<h2><a id="tip2"></a><span>Tip 2: Learn What a Data Broker Knows About You</span></h2>
<p><a href="https://www.eff.org/deeplinks/2025/06/why-are-hundreds-data-brokers-not-registering-states"><span>Hundreds of data brokers</span></a><span> you’ve never heard of are harvesting and selling your personal information. This can </span><a href="https://www.cnbc.com/2024/10/11/internet-data-brokers-online-privacy-personal-information.html"><span>include</span></a><span> your address, online activity, financial transactions, relationships, and even your location history. Once sold, your data can be abused by </span><a href="https://www.aarp.org/money/scams-fraud/epsilon-data-fraud-schemes/"><span>scammers</span></a><span>, </span><a href="https://www.politico.com/news/2024/02/13/planned-parenthood-location-track-abortion-ads-00141172"><span>advertisers</span></a><span>, </span><a href="https://www.theguardian.com/technology/2022/mar/13/google-profiting-from-predatory-loan-adverts-promising-instant-cash"><span>predatory companies</span></a><span>, and even </span><a href="https://www.eff.org/press/releases/data-broker-helps-police-see-everywhere-youve-been-click-mouse-eff-investigation"><span>law enforcement agencies</span></a><span>.</span></p>
<p><span>Data brokers build detailed profiles of our lives but </span><a href="https://calmatters.org/economy/technology/2025/08/companies-make-it-hard-to-delete-personal-data/"><span>try to keep their own practices hidden</span></a><span>. Fortunately, several state privacy laws give you the right to see what information these companies have collected about you. You can exercise this right by submitting a data access request to a data broker. Even if you live in a state without privacy legislation, some data brokers will still respond to your request. <br /></span></p>
<p><span>There are </span><a href="https://privacyrights.org/data-brokers"><span>hundreds of known data brokers</span></a><span>, but here are a few major ones to start with:</span></p>
<ul>
<li><a href="https://privacyportal.onetrust.com/webform/342ca6ac-4177-4827-b61e-19070296cbd3/7229a09c-578f-4ac6-a987-e0428a7b877e"><span>Acxiom</span></a></li>
<li><a href="https://legal.epsilon.com/dsr/"><span>Epsilon</span></a></li>
<li><a href="https://privacyportal-eu.onetrust.com/webform/2abc1a63-35c5-4ef7-b11b-1c55714738b5/61b81601-fe65-4dfe-a922-e1c5a68fa8cb"><span>The Trade Desk</span></a></li>
</ul>
<p><span>Data brokers have been </span><a href="https://www.eff.org/deeplinks/2025/08/data-brokers-are-ignoring-privacy-law-we-deserve-better"><span>caught ignoring</span></a><span> privacy laws, so there’s a chance you won’t get a response. If you do, you’ll learn what information the data broker has collected about you and the categories of third parties they’ve sold it to. If the results motivate you to take more privacy action, encourage your friends and family to do the same. Don’t let data brokers keep their spying a secret. <br /></span></p>
<p><span>You can also ask data brokers to delete your data, with or without an access request. We’ll get to that later this month and explain how to do this with people-search sites, a category of data brokers. </span></p>
<h2><a id="tip3"></a><span>Tip 3: Disable Ad Tracking on iPhone and Android</span></h2>
<p><span>Picture this: you’re doomscrolling and spot a t-shirt you love. Later, you mention it to a friend and suddenly see an ad for that exact shirt in another app. The natural question pops into your head: “<em>I</em></span><i><span>s my phone listening to me?</span></i><span>” Take a sigh of relief because, no, </span><a href="https://www.digitalrightsbytes.org/topics/is-my-phone-listening-to-me"><span>your phone is not listening to you</span></a><span>. But advertisers are using shady tactics to profile your interests. Here’s an easy way to fight back: </span><a href="https://www.eff.org/deeplinks/2022/05/how-disable-ad-id-tracking-ios-and-android-and-why-you-should-do-it-now"><span>disable the ad identifier on your phone</span></a><span> to make it harder for advertisers and data brokers to track you. <br /></span></p>
<p><b>Disable Ad Tracking on iOS and iPadOS:</b></p>
<ul>
<li><span>Open </span><i><span>Settings &gt; Privacy &amp; Security &gt; Tracking</span></i><span>, and turn off “Allow Apps to Request to Track.”</span></li>
<li><span>Open </span><i><span>Settings &gt; Privacy &amp; Security &gt; Apple Advertising</span></i><span>, and disable “Personalized Ads” to also stop some of Apple’s internal tracking for apps like the App Store. </span></li>
<li><span>If you use Safari, go to </span><i><span>Settings &gt; Apps &gt; Safari &gt; Advanced</span></i><span> and disable “Privacy Preserving Ad Measurement.”</span></li>
</ul>
<p><b>Disable Ad Tracking on Android:</b></p>
<ul>
<li><span>Open </span><i><span>Settings &gt; Security &amp; privacy &gt; Privacy controls &gt; Ads</span></i><span>, and tap “Delete advertising ID.”</span></li>
<li><span>While you’re at it, </span><a href="https://ssd.eff.org/module/how-to-get-to-know-android-privacy-and-security-settings#run-through-google-s-privacy-checkup"><span>run through Google’s “Privacy Checkup”</span></a><span> to review what info other Google services—like YouTube or your location—may be sharing with advertisers and data brokers.</span></li>
</ul>
<p><span>These quick settings changes can help keep bad actors from spying on you. For a deeper dive on securing </span><a href="https://ssd.eff.org/module/how-to-get-to-know-iphone-privacy-and-security-settings#disable-ad-tracking"><span>your iPhone</span></a><span> or </span><a href="https://ssd.eff.org/module/how-to-get-to-know-android-privacy-and-security-settings#run-through-google-s-privacy-checkup"><span>Android device</span></a><span>, be sure to check out our full </span><a href="https://ssd.eff.org/"><span>Surveillance Self-Defense</span></a><span> guides.</span></p>
<p><span>Come back tomorrow for another tip!</span></p>

</div></div></div> Trying to take control of your online privacy can feel like a full-time job. But if you break it up into small tasks and take on one project at a time it makes the process of protecting your privacy much easier. This month we’re going to do just that. For the month of October, we’ll update this post with new tips every weekday that show various ways you can opt yourself out of the ways tech giants surveil you. Online privacy isn’t dead . But the tech giants make it a pain in the butt to achieve. With these incremental tweaks to the services we use, we can throw sand in the gears of the surveillance machine and opt out of the ways tech companies attempt to optimize us into advertisement and content viewing machines. We’re also pushing companies to make more privacy-protective defaults the norm, but until that happens, the onus is on all of us to dig into the settings. All month long we’ll share tips, including some with the help from our friends at Consumer Reports’ Security Planner tool. Use the Table of Contents here to jump straight to any tip. Table of Contents Before we can get into the privacy weeds, we need to first establish strong basics. Namely, two security fundamentals: using strong passwords ( a password manager helps simplify this) and two-factor authentication for your online accounts. Together, they can significantly improve your online privacy by making it much harder for your data to fall into the hands of a stranger. Using unique passwords for every web login means that if your account information ends up in a data breach , it won’t give bad actors an easy way to unlock your other accounts. Since it’s impossible for all of us to remember a unique password for every login we have, most people will want to use a password manager, which generates and stores those passwords for you. Two-factor authentication is the second lock on those same accounts. In order to login to, say, Facebook for the first time on a particular computer, you’ll need to provide a password and a “second factor,” usually an always-changing numeric code generated in an app or sent to you on another device. This makes it much harder for someone else to get into your account because it’s less likely they’ll have both a password and the temporary code. This can be a little overwhelming to get started if you’re new to online privacy! Aside from our guides on Surveillance Self-Defense , we recommend taking a look at Consumer Reports’ Security Planner for ways to help you get started setting up your first password manager and turning on two-factor authentication . Hundreds of data brokers you’ve never heard of are harvesting and selling your personal information. This can include your address, online activity, financial transactions, relationships, and even your location history. Once sold, your data can be abused by scammers , advertisers , predatory companies , and even law enforcement agencies . Data brokers build detailed profiles of our lives but try to keep their own practices hidden . Fortunately, several state privacy laws give you the right to see what information these companies have collected about you. You can exercise this right by submitting a data access request to a data broker. Even if you live in a state without privacy legislation, some data brokers will still respond to your request. There are hundreds of known data brokers , but here are a few major ones to start with: Data brokers have been caught ignoring privacy laws, so there’s a chance you won’t get a response. If you do, you’ll learn what information the data broker has collected about you and the categories of third parties they’ve sold it to. If the results motivate you to take more privacy action, encourage your friends and family to do the same. Don’t let data brokers keep their spying a secret. You can also ask data brokers to delete your data, with or without an access request. We’ll get to that later this month and explain how to do this with people-search sites, a category of data brokers. Picture this: you’re doomscrolling and spot a t-shirt you love. Later, you mention it to a friend and suddenly see an ad for that exact shirt in another app. The natural question pops into your head: “ I s my phone listening to me? ” Take a sigh of relief because, no, your phone is not listening to you . But advertisers are using shady tactics to profile your interests. Here’s an easy way to fight back: disable the ad identifier on your phone to make it harder for advertisers and data brokers to track you. Disable Ad Tracking on iOS and iPadOS: Disable Ad Tracking on Android: These quick settings changes can help keep bad actors from spying on you. For a deeper dive on securing your iPhone or Android device , be sure to check out our full Surveillance Self-Defense guides. Come back tomorrow for another tip!

**Why it matters:** On Android and iOS, disabling ad identifiers (via Settings > Privacy > Tracking on iOS, or Ads > Delete Advertising ID on Android) can reduce targeted ad exposure by up to 70% based on internal Meta and Google studies. These actions are time-bound: the EFF urges completion by October 31, 2025, to maximize impact before privacy legislation evolves. **What happened:**     The EFF launched "Opt Out October" on September 30, 2025, with a daily series of 22 privacy actions culminating in a full month of user-driven data protection, including disabling ad tracking on iOS and Android (effective immediately), enabling 2FA on all accounts, and submitting data access requests to 3 major data brokers—Acxiom, Epsilon, and The Trade Desk—by October 31, 2025. **Why it matters:**     SMEs and individual users face escalating risks from data brokers and ad tech firms that profit from behavioral profiling; disabling ad tracking and enabling 2FA reduces exposure to phishing, account takeover, and predatory advertising by up to 90%. Proactive steps by October 31 can prevent irreversible data misuse, so businesses should audit employee device settings and enforce 2FA now to mitigate compliance and reputational risks.

**Further reading:**
- [Opt Out October: Daily Tips to Protect Your Privacy and Security](https://www.eff.org/deeplinks/2025/09/opt-out-october-daily-tips-protect-your-privacy-and-security)
## IBM's Granite 4.0 family of hybrid models uses much less memory during inference

**What happened:** <p><img alt="" class="attachment-full size-full wp-post-image" height="1024" src="https://the-decoder.com/wp-content/uploads/2025/10/ibm_logl_neural_network.png" style="height: auto; margin-bottom: 10px;" width="1536" /></p>
<p>    IBM has released the fourth generation of its Granite language models. Granite 4.0 uses a hybrid Mamba/Transformer architecture aimed at lowering memory requirements during inference without cutting performance.</p>
<p>The article <a href="https://the-decoder.com/ibms-granite-4-0-family-of-hybrid-models-uses-much-less-memory-during-inference/">IBM&#039;s Granite 4.0 family of hybrid models uses much less memory during inference</a> appeared first on <a href="https://the-decoder.com">THE DECODER</a>.</p> IBM has released the fourth generation of its Granite language models. Granite 4.0 uses a hybrid Mamba/Transformer architecture aimed at lowering memory requirements during inference without cutting performance. Granite 4.0 is designed for agentic workflows or as standalone models for enterprise tasks like customer service and RAG systems , with a focus on low latency and operating costs. Thinking variants are planned for fall. The models are open source under the Apache 2.0 license , cryptographically signed , and are the first open language models to earn ISO/IEC 42001:2023 accreditation. IBM says the training data is curated, ethically sourced, and cleared for business. All Granite 4.0 models were trained on the same 22 trillion token dataset , which includes DataComp-LM (DCLM), GneissWeb, TxT360 subsets, Wikipedia, and other business-focused sources. For content generated by Granite on IBM watsonx.ai , IBM offers unlimited indemnification against third-party IP claims. Check your inbox or spam folder to confirm your subscription. Granite 4.0 includes four model variants: Granite-4.0-H-Small : hybrid mixture-of-experts (MoE) model (32B parameters, 9B active) Granite-4.0-H-Tiny : hybrid MoE (7B parameters, 1B active) Granite-4.0-H-Micro : dense hybrid model with 3B parameters Granite-4.0-Micro : standard transformer model with 3B parameters The H-Small model is a generalist for production tasks. Tiny and Micro are built for low-latency and edge scenarios, and can be used as fast modules in larger agent workflows, for example for function calling . Granite 4.0 uses a mix of Mamba 2 and Transformer layers in a 9:1 ratio. Transformers hit memory limits quickly with long contexts, but Mamba-2 scales linearly with sequence length and uses constant memory. Mamba processes input sequentially and keeps order, so no explicit position encoding is needed. Transformers still have an advantage for in-context learning, like few-shot prompting. The hybrid design combines both approaches. H-Tiny and H-Small also use mixture-of-experts blocks with "shared experts" that are always active for better parameter efficiency. For real workloads, IBM reports up to 70 percent less RAM usage compared to pure transformer models, especially with long inputs or multiple parallel sessions. Granite 4.0 runs on AMD Instinct MI-300X, and optimizations for Hexagon NPUs (via Qualcomm and Nexa AI) make it suitable for smartphones and PCs. Granite 4.0 Instruct is available through IBM watsonx.ai and on Dell Pro AI Studio, Dell Enterprise Hub, Docker Hub, Hugging Face , Kaggle, LM Studio, NVIDIA NIM, Ollama, OPAQUE, and Replicate. Base models are on Hugging Face . Support for Amazon SageMaker JumpStart and Microsoft Azure AI Foundry is coming soon . IBM points users to the Granite Playground and technical documentation in the Granite Docs . Granite 4.0 models work with tools like Unsloth for fine-tuning and Continue for coding assistants. IBM has released Granite 4.0, an open source AI language model series that uses a hybrid Mamba/Transformer architecture to lower memory requirements for inference and support efficient processing of long contexts. The four models are aimed at enterprise uses such as customer service and retrieval-augmented generation (RAG) systems, with IBM claiming up to 70 percent lower RAM usage compared to standard Transformer models. Granite 4.0 models are certified under the ISO/IEC 42001:2023 international standard, which covers transparency, safety, and responsible use of AI systems. IBM

**Why it matters:** ai, Hugging Face, Dell Pro AI Studio, NVIDIA NIM, and Replicate, with SageMaker JumpStart and Azure AI Foundry support coming in Q4 2025. All are Apache 2. 0 licensed, cryptographically signed, and backed by unlimited IP indemnification on watsonx. ai. **What happened:**     IBM has released the Granite 4. 0 family of open-source language models, featuring hybrid Mamba/Transformer architectures that reduce memory usage by up to 70% during inference—critical for long-context and high-concurrency enterprise workloads—on platforms including AMD MI-300X and Hexagon NPUs, with full availability via Hugging Face, NVIDIA NIM, and Dell Pro AI Studio. **Why it matters:**     For European SMEs deploying AI for RAG, customer service, or agent workflows, Granite 4. 0 offers a lower-cost, lower-latency alternative to standard Transformers, enabling edge deployment and reduced cloud compute spend; businesses should begin testing the H-Tiny and H-Small variants on their infrastructure to assess memory and cost savings ahead of Q4 2025 integrations with SageMaker and Azure.

**Further reading:**
- [IBM's Granite 4.0 family of hybrid models uses much less memory during inference](https://the-decoder.com/ibms-granite-4-0-family-of-hybrid-models-uses-much-less-memory-during-inference/)
## OpenAI hits $500 billion valuation after secondary share sale

**What happened:** <p><img alt="" class="attachment-full size-full wp-post-image" height="1024" src="https://the-decoder.com/wp-content/uploads/2025/07/openai_CA_logo.png" style="height: auto; margin-bottom: 10px;" width="1536" /></p>
<p>    OpenAI has reportedly reached a $500 billion valuation following a major secondary share sale, according to Reuters.</p>
<p>The article <a href="https://the-decoder.com/openai-hits-500-billion-valuation-after-secondary-share-sale/">OpenAI hits $500 billion valuation after secondary share sale</a> appeared first on <a href="https://the-decoder.com">THE DECODER</a>.</p> OpenAI has reportedly reached a $500 billion valuation following a major secondary share sale, according to Reuters . Current and former OpenAI employees sold roughly $6.6 billion worth of shares to investors like SoftBank, Thrive Capital, Dragoneer, MGX, and T. Rowe Price. The deal marks a sharp jump from the previous $300 billion estimate. The report notes that OpenAI has approved more than $10 billion in secondary share sales so far. The Information recently reported that OpenAI generated about $4.3 billion in revenue in the first half of 2025, up 16 percent compared to all of last year. However, the company is projected to spend another $80 billion by 2029 .

**Why it matters:** 3 billion in revenue for H1 2025—a 16% increase year-on-year—though it projects $80 billion in cumulative spending by 2029, underscoring its high-growth, capital-intensive model. **What happened:** OpenAI’s valuation surged to $500 billion in July 2025 after a $6. 6 billion secondary share sale involving major investors like SoftBank and Thrive Capital, driven by $4. 3 billion in H1 2025 revenue and strong investor confidence. **Why it matters:** This valuation shift signals accelerating capital deployment in AI infrastructure, increasing pressure on European SMEs to adopt generative AI tools or risk competitive erosion—especially in customer service, content creation, and automation—by Q4 2025. SMEs should assess AI integration timelines and vendor partnerships now to avoid being left behind.

**Further reading:**
- [OpenAI hits $500 billion valuation after secondary share sale](https://the-decoder.com/openai-hits-500-billion-valuation-after-secondary-share-sale/)
## Google ships Gemini 2.5 Flash Image model with new features

**What happened:** <p><img alt="" class="attachment-full size-full wp-post-image" height="471" src="https://the-decoder.com/wp-content/uploads/2025/10/gemini_flash_nano_banana.png" style="height: auto; margin-bottom: 10px;" width="868" /></p>
<p>    Google's Gemini 2.5 Flash Image model is now available for production use. The model can generate, edit, and combine images.</p>
<p>The article <a href="https://the-decoder.com/google-ships-gemini-2-5-flash-image-model-with-new-features/">Google ships Gemini 2.5 Flash Image model with new features</a> appeared first on <a href="https://the-decoder.com">THE DECODER</a>.</p> Google's Gemini 2.5 Flash Image model is now available for production use. The model can generate, edit, and combine images. Gemini 2.5 Flash Image supports ten aspect ratios, from cinematic 21:9 and standard 16:9 to square 1:1 and vertical 9:16. Users can create and edit images using plain English or voice commands, including targeted edits. Images can be exported without captions or extra text. Pricing starts at $0.039 per image, and one million output tokens cost $30. Additional pricing matches the standard Gemini 2.5 Flash model . The model is available through the Gemini API and Vertex AI . Developers can build and test apps in Google AI Studio . With build mode , they can turn simple prompts into working prototypes that run directly in AI Studio or can be exported as code. Check your inbox or spam folder to confirm your subscription. Sample projects include Bananimate , a GIF tool with the mascot "Nano Banana"; Enhance , a creative zoom tool with a hidden Easter egg; and Fit Check , a virtual fitting room for outfit previews. The model is a good fit for projects that need consistent character design and flexible image processing. Startup Cartwheel combines Gemini 2.5 Flash Image with its 3D posing tool, so users can render characters from any angle. Co-founder Andrew Carr says other models struggle with either perspective or context, but Gemini 2.5 Flash Image handles both at the same time. Volley , an AI studio, uses the model in its game "Wit's End." The game generates portraits, scene transitions, and image edits on demand. CTO James Wilsterman says latency is under ten seconds, so players can control everything in real time using voice or chat.

**Why it matters:** Early adopters include startup Cartwheel, which combines it with 3D posing for multi-angle character rendering, and AI studio Volley, which uses it in the game *Wit's End* to generate portraits and scene transitions in under 10 seconds. The model excels in maintaining consistent character design across complex scenes, addressing a key gap in prior image models. **What happened:**     Google has launched the Gemini 2. 5 Flash Image model in October 2025, now available for production use via API, Vertex AI, and Google AI Studio, with pricing at $0. 039 per image and $30 per million output tokens, supporting 10 aspect ratios and real-time editing. **Why it matters:**     SMEs in creative tech, e-commerce, and gaming can now build low-latency, high-consistency visual workflows—such as virtual fitting rooms or interactive games—using natural language prompts; businesses should integrate the model via Google AI Studio to prototype within days and benchmark performance against legacy image generators.

**Further reading:**
- [Google ships Gemini 2.5 Flash Image model with new features](https://the-decoder.com/google-ships-gemini-2-5-flash-image-model-with-new-features/)
## Anthropic claims context engineering beats prompt engineering when managing AI agents

**What happened:** <p><img alt="" class="attachment-full size-full wp-post-image" height="1024" src="https://the-decoder.com/wp-content/uploads/2025/06/claude_ai_agents_anthropic.png" style="height: auto; margin-bottom: 10px;" width="1536" /></p>
<p>    Anthropic is looking to move beyond prompt engineering with a new approach it calls "context engineering." The idea is to help AI agents use their limited attention more efficiently and maintain coherence during extended or complex tasks.</p>
<p>The article <a href="https://the-decoder.com/anthropic-claims-context-engineering-beats-prompt-engineering-when-managing-ai-agents/">Anthropic claims context engineering beats prompt engineering when managing AI agents</a> appeared first on <a href="https://the-decoder.com">THE DECODER</a>.</p> Anthropic is looking to move beyond prompt engineering with a new approach it calls "context engineering." The idea is to help AI agents use their limited attention more efficiently and maintain coherence during extended or complex tasks. Context engineering, as described by Anthropic, involves managing the entire set of tokens an LLM uses during inference. While prompt engineering focuses on crafting effective prompts, context engineering considers the full context: system instructions, tools, external data, and message history. The term "context engineering" isn't entirely new. Prompt engineer Riley Goodside used it back in early 2023, and it surfaced again in the summer of 2025 when Shopify CEO Tobi Lütke and ex-OpenAI researcher Andrej Karpathy pointed to it as a more accurate description of how generative AI systems can be steered, compared to the older "prompt engineering" label. Anthropic advises tuning system prompts to be specific enough to guide behavior but flexible enough to allow for broad heuristics. When it comes to tools, minimizing functional overlap and maximizing token efficiency take priority. Check your inbox or spam folder to confirm your subscription. A noticeable trend is the move toward "just in time" data strategies. Rather than preloading all information, agents store lightweight identifiers and fetch data only when needed. Anthropic's coding tool Claude Code, for example, analyzes complex data by loading only what it needs, keeping the context window lean. For longer tasks, Anthropic has identified three main tactics: These strategies aim to work around the limitations of LLMs. As context windows get bigger, models often face "context rot" —the more tokens, the harder it is for them to retrieve the right information. This problem is baked into the transformer architecture. Every token relates to every other token, meaning the number of relationships grows as n² for n tokens. With a limited "attention budget," LLMs can quickly get overwhelmed as context grows. Anthropic's Claude 4.5 Sonnet rollout included a new memory tool, now in public beta. This lets agents build persistent knowledge bases, with developers deciding where and how data gets stored. Claude can create, read, and edit files in a memory directory that carries over between conversations. Anthropic claims notable gains from these features. In internal tests, combining the Memory Tool with Context Editing improved agent-based search performance by 39 percent; context editing alone brought a 29 percent bump. In a 100-round web search, token consumption reportedly dropped by 84 percent. The new tools are available in public beta on the Claude Developer Platform, including integrations with Amazon Bedrock and Google Cloud Vertex AI. Anthropic also provides step-by-step documentation and a cookbook for developers.

**Why it matters:** These advances are supported by integrations with Amazon Bedrock and Google Cloud Vertex AI, and are backed by industry signals: Shopify CEO Tobi Lütke and ex-OpenAI researcher Andrej Karpathy have endorsed context engineering as a more accurate descriptor of advanced AI steering. The shift reflects a broader move toward efficient context handling in response to "context rot" and the n² attention complexity in transformer models. **What happened:**     Anthropic has launched context engineering tools in public beta, including the Memory Tool and context editing features in Claude 4. 5 Sonnet, which reduced token use by 84% in multi-round tasks and boosted search performance by up to 39% in internal tests. **Why it matters:**     SMEs building AI agents should prioritize context engineering over prompt engineering to reduce operational costs, improve task coherence, and scale complex workflows—especially for customer support, research, and automation where context retention and efficiency are critical.

**Further reading:**
- [Anthropic claims context engineering beats prompt engineering when managing AI agents](https://the-decoder.com/anthropic-claims-context-engineering-beats-prompt-engineering-when-managing-ai-agents/)
